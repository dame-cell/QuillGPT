# SmallGPT 
SmallGPT is a project focused on exploring and optimizing large language models (LLMs) by leveraging the GPT-2 architecture to generate text in the style of Shakespeare.

- We use the shakespere dataset usually used by Andrej karpathy because its easier to manage and its also quite small 
- The model is very small , with  134,117,376  parameter 

# Examples 

# Get Started 

# Hyper-Parameters 

# Loss and Eval loss 

