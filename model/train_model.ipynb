{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 134,117,376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6540b0bf30204bbab9c15423e3845e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 - Train Loss: 5.7158, Validation Loss: 5.9255\n",
      "Sample text: All:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f0dc38a53149979c5a643100d0245c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 - Train Loss: 5.0909, Validation Loss: 5.4978\n",
      "Sample text: All:\n",
      "I'll you,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I'll:\n",
      "\n",
      "I'll you\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80305e450704e13ac9e7fb2024507c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 - Train Loss: 4.7138, Validation Loss: 5.2847\n",
      "Sample text: All:\n",
      "I'll not a man,\n",
      "I am a man,\n",
      "I am a man,\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a188d0a4a08e4746b3a7c7e7dcf7af18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 - Train Loss: 4.4329, Validation Loss: 5.1599\n",
      "Sample text: All:\n",
      "I am not,\n",
      "I am not,\n",
      "\n",
      "\n",
      "\n",
      "I'll be a little of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e246f7efa501429a8cd1fcfbcef2c0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 - Train Loss: 4.0885, Validation Loss: 5.0594\n",
      "Sample text: All:\n",
      "I am not, and let me,\n",
      "And I am a gentleman,\n",
      "And,\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6eca1fc19a422e969164879aeaa134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 - Train Loss: 3.7864, Validation Loss: 5.0295\n",
      "Sample text: All:\n",
      "I do not my lord,\n",
      "And take my lord,\n",
      "And I am not my lord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4146d1554d524b6eb5e8bd8d30439ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 - Train Loss: 3.4899, Validation Loss: 5.0701\n",
      "Sample text: All:\n",
      "I do not my lord,\n",
      "And therefore,\n",
      "That I'll be a better-morrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8baaa7fa8a49889988829a25bf16a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 - Train Loss: 3.1726, Validation Loss: 5.1430\n",
      "Sample text: All:\n",
      "I do not my lord:\n",
      "I'll do me;\n",
      "I'll do not a my\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af66895069044721880d47b9118c8369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 - Train Loss: 2.7689, Validation Loss: 5.1795\n",
      "Sample text: All:\n",
      "O:\n",
      "O:\n",
      "O, sir!\n",
      "\n",
      "DUKE VINCENTIO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90aa270abdf345fba28137ca538ddc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tiktoken\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from modeling_gpt2 import GPT2\n",
    "from utils import create_dataloader_v1\n",
    "import requests\n",
    "\n",
    "# Configuration for GPT-2 model\n",
    "GPT_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_len\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"num_heads\": 12,\n",
    "    \"num_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "# Training Hyperparameters\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 3e-4\n",
    "BATCH_SIZE = 16\n",
    "EVAL_INTERVAL = 100  # Evaluate every 100 steps\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "START_CONTEXT = \"All:\"\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Load the GPT-2 model\n",
    "model = GPT2(GPT_CONFIG).to(DEVICE)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n",
    "\n",
    "# Function to load text data\n",
    "def load_text_file(path_to_text=None, url=None):\n",
    "    if path_to_text:\n",
    "        with open(path_to_text, 'r', encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "    elif url:\n",
    "        response = requests.get(url)\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Load dataset\n",
    "text = load_text_file(path_to_text=\"/teamspace/studios/this_studio/GPT2/model/shakespeare.txt\")\n",
    "split_idx = int(0.90 * len(text))\n",
    "train_data, val_data = text[:split_idx], text[split_idx:]\n",
    "\n",
    "# Create DataLoader for training and validation\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=GPT_CONFIG['context_len'],\n",
    "    stride=GPT_CONFIG['context_len'],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=GPT_CONFIG['context_len'],\n",
    "    stride=GPT_CONFIG['context_len'],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Initialize optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# Helper functions for encoding/decoding text\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    return tokenizer.decode(token_ids.squeeze(0).tolist())  # Remove batch dimension\n",
    "\n",
    "# Functions to calculate loss and evaluate the model\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    return F.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    num_batches = min(num_batches or len(data_loader), 100)  # Limit to 100 batches for faster evaluation\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            total_loss += calc_loss_batch(input_batch, target_batch, model, device).item()\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def generate(model, device, idx, max_new_tokens, context_len):\n",
    "    idx = idx.to(device)  \n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_context = idx[:, -context_len:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            idx_context = idx_context.to(device)\n",
    "            logits = model(idx_context)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "            idx = torch.cat((idx, idx_next), dim=-1)\n",
    "    \n",
    "    return idx\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "# Lists to track metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "grad_norms = []\n",
    "step_times = []\n",
    "learning_rates = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    for step, (x, y) in progress_bar:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = calc_loss_batch(x, y, model, DEVICE)\n",
    "        loss.backward()\n",
    "        \n",
    "        norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        train_losses.append(loss.item())\n",
    "        grad_norms.append(norm)\n",
    "        step_times.append(time.time() - start_time)\n",
    "        learning_rates.append(scheduler.get_last_lr()[0])\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'grad_norm': f\"{norm:.4f}\",\n",
    "            'step_time': f\"{step_times[-1]:.4f}s\",\n",
    "            'lr': f\"{learning_rates[-1]:.6f}\"\n",
    "        })\n",
    "        \n",
    "        if (step + 1) % EVAL_INTERVAL == 0:\n",
    "            train_loss, val_loss = evaluate_model(model, train_loader, val_loader, DEVICE)\n",
    "            print(f\"\\nStep {step+1} - Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "            \n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    # End of epoch evaluation\n",
    "    train_loss, val_loss = evaluate_model(model, train_loader, val_loader, DEVICE)\n",
    "    print(f\"\\nEpoch {epoch+1} - Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "        # Generate sample text\n",
    "    token_ids = generate(\n",
    "                model=model,\n",
    "                device=DEVICE,\n",
    "                idx=text_to_token_ids(START_CONTEXT, tokenizer),\n",
    "                max_new_tokens=20,\n",
    "                context_len=GPT_CONFIG[\"context_len\"],\n",
    "    )\n",
    "    print(\"Sample text:\", token_ids_to_text(token_ids, tokenizer))\n",
    "    \n",
    "\n",
    "# Final evaluation\n",
    "final_train_loss, final_val_loss = evaluate_model(model, train_loader, val_loader, DEVICE)\n",
    "print(f\"\\nFinal - Train Loss: {final_train_loss:.4f}, Validation Loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "First Citizen:\n",
    "Very well; and could be\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "            model=model,\n",
    "            device=DEVICE,\n",
    "            idx=text_to_token_ids(txt, tokenizer),\n",
    "            max_new_tokens=100,\n",
    "            context_len=GPT_CONFIG[\"context_len\"]\n",
    "            )\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"model.pth\",\n",
    "    path_in_repo=\"gpt_model.pt\",\n",
    "    repo_id=\"damerajee/smallgpt\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
